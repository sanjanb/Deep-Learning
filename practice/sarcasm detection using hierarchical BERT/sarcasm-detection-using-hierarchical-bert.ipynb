{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":36545,"sourceType":"datasetVersion","datasetId":1309}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T07:26:25.396193Z","iopub.execute_input":"2025-12-04T07:26:25.396563Z","iopub.status.idle":"2025-12-04T07:26:25.407430Z","shell.execute_reply.started":"2025-12-04T07:26:25.396532Z","shell.execute_reply":"2025-12-04T07:26:25.405668Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/sarcasm/train-balanced-sarc.csv.gz\n/kaggle/input/sarcasm/train-balanced-sarcasm.csv\n/kaggle/input/sarcasm/test-balanced.csv\n/kaggle/input/sarcasm/test-unbalanced.csv\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"## IMPORT ALL THE NECESSARY LIBRARIES AND DATASETS","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport warnings\n\nfrom tensorflow import keras\nfrom transformers import BertTokenizer, TFBertModel\nfrom sklearn.model_selection import train_test_split\n\nwarnings.filterwarnings(\"ignore\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T08:02:39.904120Z","iopub.execute_input":"2025-12-04T08:02:39.905113Z","iopub.status.idle":"2025-12-04T08:02:41.991912Z","shell.execute_reply.started":"2025-12-04T08:02:39.905078Z","shell.execute_reply":"2025-12-04T08:02:41.990760Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/sarcasm/train-balanced-sarcasm.csv\")\n\ntrain.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T07:26:25.427192Z","iopub.execute_input":"2025-12-04T07:26:25.427803Z","iopub.status.idle":"2025-12-04T07:26:30.895260Z","shell.execute_reply.started":"2025-12-04T07:26:25.427774Z","shell.execute_reply":"2025-12-04T07:26:30.894001Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"   label                                            comment     author  \\\n0      0                                         NC and NH.  Trumpbart   \n1      0  You do know west teams play against west teams...  Shbshb906   \n2      0  They were underdogs earlier today, but since G...   Creepeth   \n3      0  This meme isn't funny none of the \"new york ni...  icebrotha   \n4      0                    I could use one of those tools.  cush2push   \n\n            subreddit  score  ups  downs     date          created_utc  \\\n0            politics      2   -1     -1  2016-10  2016-10-16 23:55:23   \n1                 nba     -4   -1     -1  2016-11  2016-11-01 00:24:10   \n2                 nfl      3    3      0  2016-09  2016-09-22 21:45:37   \n3  BlackPeopleTwitter     -8   -1     -1  2016-10  2016-10-18 21:03:47   \n4  MaddenUltimateTeam      6   -1     -1  2016-12  2016-12-30 17:00:13   \n\n                                      parent_comment  \n0  Yeah, I get that argument. At this point, I'd ...  \n1  The blazers and Mavericks (The wests 5 and 6 s...  \n2                            They're favored to win.  \n3                         deadass don't kill my buzz  \n4  Yep can confirm I saw the tool they use for th...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>comment</th>\n      <th>author</th>\n      <th>subreddit</th>\n      <th>score</th>\n      <th>ups</th>\n      <th>downs</th>\n      <th>date</th>\n      <th>created_utc</th>\n      <th>parent_comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NC and NH.</td>\n      <td>Trumpbart</td>\n      <td>politics</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2016-10</td>\n      <td>2016-10-16 23:55:23</td>\n      <td>Yeah, I get that argument. At this point, I'd ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>You do know west teams play against west teams...</td>\n      <td>Shbshb906</td>\n      <td>nba</td>\n      <td>-4</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2016-11</td>\n      <td>2016-11-01 00:24:10</td>\n      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>They were underdogs earlier today, but since G...</td>\n      <td>Creepeth</td>\n      <td>nfl</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2016-09</td>\n      <td>2016-09-22 21:45:37</td>\n      <td>They're favored to win.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>This meme isn't funny none of the \"new york ni...</td>\n      <td>icebrotha</td>\n      <td>BlackPeopleTwitter</td>\n      <td>-8</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2016-10</td>\n      <td>2016-10-18 21:03:47</td>\n      <td>deadass don't kill my buzz</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>I could use one of those tools.</td>\n      <td>cush2push</td>\n      <td>MaddenUltimateTeam</td>\n      <td>6</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2016-12</td>\n      <td>2016-12-30 17:00:13</td>\n      <td>Yep can confirm I saw the tool they use for th...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T07:26:30.896502Z","iopub.execute_input":"2025-12-04T07:26:30.897050Z","iopub.status.idle":"2025-12-04T07:26:30.903894Z","shell.execute_reply.started":"2025-12-04T07:26:30.897024Z","shell.execute_reply":"2025-12-04T07:26:30.902948Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"(1010826, 10)"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T07:26:30.905784Z","iopub.execute_input":"2025-12-04T07:26:30.906421Z","iopub.status.idle":"2025-12-04T07:26:31.291931Z","shell.execute_reply.started":"2025-12-04T07:26:30.906374Z","shell.execute_reply":"2025-12-04T07:26:31.290704Z"}},"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"label              0\ncomment           55\nauthor             0\nsubreddit          0\nscore              0\nups                0\ndowns              0\ndate               0\ncreated_utc        0\nparent_comment     0\ndtype: int64"},"metadata":{}}],"execution_count":44},{"cell_type":"markdown","source":"## DATA PROCESSING","metadata":{}},{"cell_type":"code","source":"# lets take only 10k rows to make the operations more easier\n\ndf = train[:10000]\ndf = df[['label', 'comment']]\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T07:26:31.293054Z","iopub.execute_input":"2025-12-04T07:26:31.293369Z","iopub.status.idle":"2025-12-04T07:26:31.306149Z","shell.execute_reply.started":"2025-12-04T07:26:31.293342Z","shell.execute_reply":"2025-12-04T07:26:31.304944Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"   label                                            comment\n0      0                                         NC and NH.\n1      0  You do know west teams play against west teams...\n2      0  They were underdogs earlier today, but since G...\n3      0  This meme isn't funny none of the \"new york ni...\n4      0                    I could use one of those tools.","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NC and NH.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>You do know west teams play against west teams...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>They were underdogs earlier today, but since G...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>This meme isn't funny none of the \"new york ni...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>I could use one of those tools.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T07:26:31.307241Z","iopub.execute_input":"2025-12-04T07:26:31.307638Z","iopub.status.idle":"2025-12-04T07:26:31.330554Z","shell.execute_reply.started":"2025-12-04T07:26:31.307610Z","shell.execute_reply":"2025-12-04T07:26:31.329551Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"(10000, 2)"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T07:26:31.331591Z","iopub.execute_input":"2025-12-04T07:26:31.331851Z","iopub.status.idle":"2025-12-04T07:26:31.358705Z","shell.execute_reply.started":"2025-12-04T07:26:31.331831Z","shell.execute_reply":"2025-12-04T07:26:31.357360Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"label      0\ncomment    1\ndtype: int64"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"df.dropna(inplace = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T07:26:31.359832Z","iopub.execute_input":"2025-12-04T07:26:31.360267Z","iopub.status.idle":"2025-12-04T07:26:31.385840Z","shell.execute_reply.started":"2025-12-04T07:26:31.360243Z","shell.execute_reply":"2025-12-04T07:26:31.384319Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"df.isnull().sum()\n\n# Now we have no null values in the dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T07:26:31.387014Z","iopub.execute_input":"2025-12-04T07:26:31.387290Z","iopub.status.idle":"2025-12-04T07:26:31.410000Z","shell.execute_reply.started":"2025-12-04T07:26:31.387268Z","shell.execute_reply":"2025-12-04T07:26:31.408893Z"}},"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"label      0\ncomment    0\ndtype: int64"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"# In the comment column we could have multiple datatypes, so lets clean it and keep only string type of data\n\ndf['comment'] = df['comment'].str.replace(r'[^a-zA-z\\s]', '', regex = True)\ndf.comment","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T07:26:31.411155Z","iopub.execute_input":"2025-12-04T07:26:31.411592Z","iopub.status.idle":"2025-12-04T07:26:31.457987Z","shell.execute_reply.started":"2025-12-04T07:26:31.411563Z","shell.execute_reply":"2025-12-04T07:26:31.456947Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"0                                               NC and NH\n1       You do know west teams play against west teams...\n2       They were underdogs earlier today but since Gr...\n3       This meme isnt funny none of the new york nigg...\n4                          I could use one of those tools\n                              ...                        \n9995                          probably a young latino boy\n9996                                  Dog filtergiving up\n9997                          Saturday Night dead amirite\n9998                         Moderators not fact checkers\n9999                          She hacked the online votes\nName: comment, Length: 9999, dtype: object"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"# Tokenization\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T07:28:50.628402Z","iopub.execute_input":"2025-12-04T07:28:50.629049Z","iopub.status.idle":"2025-12-04T07:28:57.277416Z","shell.execute_reply.started":"2025-12-04T07:28:50.629024Z","shell.execute_reply":"2025-12-04T07:28:57.275928Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"facdeab504d441b5abec0307c3d63f4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fc0b99b5d854ee1a06c504a76d869f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5c5b341aa1249fea29ec9ea627b05f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13537dada3244d3ab6fbf5f85a9a8b4f"}},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"# Tokenization Function\n\ndef tokenize_data(text, max_length = 100):\n    return tokenizer(\n        text.tolist(),\n        max_length = max_length,\n        truncation = True,\n        padding = 'max_length',\n        return_tensors = 'np'\n    )\n\ntokenized_data = tokenize_data(df['comment'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T07:33:05.640769Z","iopub.execute_input":"2025-12-04T07:33:05.642168Z","iopub.status.idle":"2025-12-04T07:33:09.189707Z","shell.execute_reply.started":"2025-12-04T07:33:05.642125Z","shell.execute_reply":"2025-12-04T07:33:09.188414Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"tokenized_data\n\n# The zeros are the padded data, to match the max length\n# attention mask: 1 - padded data, 0 - unpadded data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T07:34:32.128755Z","iopub.execute_input":"2025-12-04T07:34:32.129908Z","iopub.status.idle":"2025-12-04T07:34:32.138706Z","shell.execute_reply.started":"2025-12-04T07:34:32.129827Z","shell.execute_reply":"2025-12-04T07:34:32.137400Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"{'input_ids': array([[  101, 13316,  1998, ...,     0,     0,     0],\n       [  101,  2017,  2079, ...,     0,     0,     0],\n       [  101,  2027,  2020, ...,     0,     0,     0],\n       ...,\n       [  101,  5095,  2305, ...,     0,     0,     0],\n       [  101, 29420,  2015, ...,     0,     0,     0],\n       [  101,  2016, 28719, ...,     0,     0,     0]]), 'token_type_ids': array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]]), 'attention_mask': array([[1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       ...,\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0]])}"},"metadata":{}}],"execution_count":57},{"cell_type":"markdown","source":"## TRAIN TEST SPLIT","metadata":{}},{"cell_type":"code","source":"X = tokenized_data['input_ids']\ny = df['label']\n\nX.shape, y.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T07:36:40.581552Z","iopub.execute_input":"2025-12-04T07:36:40.582063Z","iopub.status.idle":"2025-12-04T07:36:40.590213Z","shell.execute_reply.started":"2025-12-04T07:36:40.582037Z","shell.execute_reply":"2025-12-04T07:36:40.588969Z"}},"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"((9999, 100), (9999,))"},"metadata":{}}],"execution_count":60},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\nX_train.shape, y_train.shape, X_test.shape, y_test.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T08:11:08.560958Z","iopub.execute_input":"2025-12-04T08:11:08.561364Z","iopub.status.idle":"2025-12-04T08:11:08.575160Z","shell.execute_reply.started":"2025-12-04T08:11:08.561334Z","shell.execute_reply":"2025-12-04T08:11:08.574063Z"}},"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"((7999, 100), (7999,), (2000, 100), (2000,))"},"metadata":{}}],"execution_count":78},{"cell_type":"code","source":"print(f\"X_train shape: {X_train.shape}\")\nprint(f\"y_train shape: {y_train.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T08:11:13.261200Z","iopub.execute_input":"2025-12-04T08:11:13.262053Z","iopub.status.idle":"2025-12-04T08:11:13.268081Z","shell.execute_reply.started":"2025-12-04T08:11:13.262023Z","shell.execute_reply":"2025-12-04T08:11:13.266744Z"}},"outputs":[{"name":"stdout","text":"X_train shape: (7999, 100)\ny_train shape: (7999,)\n","output_type":"stream"}],"execution_count":79},{"cell_type":"markdown","source":"## BUILD THE MODEL TO THE PROPOSED ARCHITECTURE\nARCHITECTURE PAPER: https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbnBpSFFjajFmNTlwUEhwR2xhelFGRGVIY294QXxBQ3Jtc0tralFJd3F4dEkwOG9oYXVvdzJvWjV2RTFLRW94MlZfNUZIcHl2dVBHXy1JUTFBcUdmSjRQWFFwYnBDNzFodTgxeEhWZU5ESzNVRjJoeVdxUjZheXlrSXljU003eFN5TWVGSXhucnZPSVBGNVRjc3RwTQ&q=https%3A%2F%2Faclanthology.org%2F2020.figlang-1.14.pdf&v=63O81OUNY_g\n\n- mixture of Encoder, CNN, LSTM, Maxpooling and Dense layers\n- This the architecture that you can find in the paper","metadata":{}},{"cell_type":"code","source":"class HierarchicalBert(tf.keras.Model):\n    def __init__(self, bert_model, lstm_units, cnn_filters, dense_units):\n        super(HierarchicalBert, self).__init__()\n        self.bert = bert_model\n\n        # Sentecne Encoding layer - Dense\n        self.dense_sentence = keras.layers.Dense(768, activation='relu')\n\n        # Context summarization layer  - Pooling\n        self.mean_pooling = keras.layers.GlobalAveragePooling1D()\n\n        # Context Encoder layer - Bidirectional LSTM\n        self.bilstm_encoder = keras.layers.Bidirectional(keras.layers.LSTM(lstm_units, return_sequences = True))\n\n        # CNN layer to capture the local features\n        self.conv = keras.layers.Conv1D(cnn_filters, 2, activation = 'relu')\n        self.pool = keras.layers.GlobalMaxPooling1D()\n\n        # Fully connected layer\n        self.dense_df = keras.layers.Dense(dense_units, activation = 'relu')\n\n        # Output layer\n        self.output_layer = keras.layers.Dense(1, activation = 'sigmoid')\n\n    def call(self, inputs):\n\n        # Bert embeddings\n        bert_output = self.bert(inputs)[0]\n\n        # Sentence encoding layer\n        sentence_encoded = self.dense_sentence(bert_output)\n\n        # Context summarization\n        context_summarized = self.mean_pooling(sentence_encoded)\n\n        # Expand the dimensions\n        context_summarized = tf.expand_dims(context_summarized, 1)\n\n        # Context encoder layer\n        context_encoded = self.bilstm_encoder(context_summarized)\n\n        # Squeesing the dimensions\n        context_encoded_squeezed = tf.squeeze(context_encoded, axis=1)\n\n        # Adding the channel dimension to match the required input shape by the CNN layer\n        context_encoded_expanded = tf.expand_dims(context_encoded_squeezed, -1)\n\n        # CNN layer\n        conv_output = self.conv(context_encoded_expanded)\n        pooled_ouput = self.pool(conv_output)\n\n        # Fully connected layer\n        dense_output = self.dense_df(pooled_ouput)\n\n        # Final Output layer\n        final_output = self.output_layer(dense_output)\n\n        return final_output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T08:18:33.145703Z","iopub.execute_input":"2025-12-04T08:18:33.147311Z","iopub.status.idle":"2025-12-04T08:18:33.159228Z","shell.execute_reply.started":"2025-12-04T08:18:33.147266Z","shell.execute_reply":"2025-12-04T08:18:33.157701Z"}},"outputs":[],"execution_count":93},{"cell_type":"code","source":"# lOADING THE TRAINED BERT MODEL\n\nbert_model = TFBertModel.from_pretrained('bert-base-uncased')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T08:03:28.384080Z","iopub.execute_input":"2025-12-04T08:03:28.385360Z","iopub.status.idle":"2025-12-04T08:03:35.262012Z","shell.execute_reply.started":"2025-12-04T08:03:28.385322Z","shell.execute_reply":"2025-12-04T08:03:35.260923Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7461a21637894dc6832d71957eca5bc4"}},"metadata":{}},{"name":"stderr","text":"2025-12-04 08:03:30.993907: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\nTensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\nSome weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"# Defining the hierarchical Bert model\n\nmodel = HierarchicalBert(bert_model, lstm_units = 128, cnn_filters = 64, dense_units = 32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T08:18:37.180647Z","iopub.execute_input":"2025-12-04T08:18:37.181013Z","iopub.status.idle":"2025-12-04T08:18:37.212069Z","shell.execute_reply.started":"2025-12-04T08:18:37.180989Z","shell.execute_reply":"2025-12-04T08:18:37.210693Z"}},"outputs":[],"execution_count":94},{"cell_type":"code","source":"# Compile the model\n\nmodel.compile(\n    optimizer='adam', \n    loss='binary_crossentropy', \n    metrics=['accuracy'] \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T08:19:58.270633Z","iopub.execute_input":"2025-12-04T08:19:58.271050Z","iopub.status.idle":"2025-12-04T08:19:58.283747Z","shell.execute_reply.started":"2025-12-04T08:19:58.271026Z","shell.execute_reply":"2025-12-04T08:19:58.282140Z"}},"outputs":[],"execution_count":97},{"cell_type":"code","source":"history = model.fit(\n    X_train, \n    y_train,\n    epochs = 5,\n    batch_size = 32,\n    validation_split = 0.2\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T08:19:59.300810Z","iopub.execute_input":"2025-12-04T08:19:59.301997Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m 20/200\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20:01\u001b[0m 7s/step - accuracy: 0.6481 - loss: 0.6618","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"loss, accuracy = model.evaluate(X_test, y_test)\nprint(f'Accuracy: {accuracy * 100}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize = (10, 4))\n\nplt.plot(history.history['accuracy'], label = \"Training Accuracy\")\nplt.plot(history.history['val_accuracy'], label = \"Validation Accuracy\")\n\nplt.title(\"Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\n\nplt.legend()\nplt.grid()\nplt.show","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}