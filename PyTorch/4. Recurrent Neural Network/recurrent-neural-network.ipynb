{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T05:27:18.205535Z","iopub.execute_input":"2025-11-27T05:27:18.205942Z","iopub.status.idle":"2025-11-27T05:27:18.523396Z","shell.execute_reply.started":"2025-11-27T05:27:18.205910Z","shell.execute_reply":"2025-11-27T05:27:18.522363Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T05:42:06.466914Z","iopub.execute_input":"2025-11-27T05:42:06.467391Z","iopub.status.idle":"2025-11-27T05:42:06.472623Z","shell.execute_reply.started":"2025-11-27T05:42:06.467356Z","shell.execute_reply":"2025-11-27T05:42:06.471738Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"## Set Device","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T05:27:26.670900Z","iopub.execute_input":"2025-11-27T05:27:26.671292Z","iopub.status.idle":"2025-11-27T05:27:26.678563Z","shell.execute_reply.started":"2025-11-27T05:27:26.671237Z","shell.execute_reply":"2025-11-27T05:27:26.677615Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Hyper Parameters","metadata":{}},{"cell_type":"code","source":"input_size = 28\nsequence_length = 28\nnum_layers = 2\nhidden_size = 256\nnum_classes = 10\nlearning_rate = 0.001\nbatch_size = 64\nepochs = 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T05:27:26.680482Z","iopub.execute_input":"2025-11-27T05:27:26.680714Z","iopub.status.idle":"2025-11-27T05:27:26.700837Z","shell.execute_reply.started":"2025-11-27T05:27:26.680695Z","shell.execute_reply":"2025-11-27T05:27:26.699904Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## RNN network","metadata":{}},{"cell_type":"code","source":"class RNN(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n        super(RNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_size * sequence_length, num_classes)\n\n    def forward(self, x):\n        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n\n        # Forward prop\n        out, _ = self.rnn(x, h0)\n        out = out.reshape(out.shape[0], -1)\n        out = self.fc(out)\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T05:44:44.871841Z","iopub.execute_input":"2025-11-27T05:44:44.872160Z","iopub.status.idle":"2025-11-27T05:44:44.878561Z","shell.execute_reply.started":"2025-11-27T05:44:44.872137Z","shell.execute_reply":"2025-11-27T05:44:44.877686Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"## Initialize the network","metadata":{}},{"cell_type":"code","source":"model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T05:44:51.868148Z","iopub.execute_input":"2025-11-27T05:44:51.869092Z","iopub.status.idle":"2025-11-27T05:44:51.877513Z","shell.execute_reply.started":"2025-11-27T05:44:51.869065Z","shell.execute_reply":"2025-11-27T05:44:51.876565Z"}},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":"## Load the data","metadata":{}},{"cell_type":"code","source":"train_dataset = datasets.MNIST(root = 'dataset/', train=True, transform = transforms.ToTensor(), download=True)\ntest_dataset = datasets.MNIST(root = 'dataset/', train=True, transform = transforms.ToTensor(), download=True)\n\ntrain_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle=True)\ntest_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T05:42:09.983467Z","iopub.execute_input":"2025-11-27T05:42:09.984302Z","iopub.status.idle":"2025-11-27T05:42:10.145515Z","shell.execute_reply.started":"2025-11-27T05:42:09.984212Z","shell.execute_reply":"2025-11-27T05:42:10.144764Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"## Loss and Optimizer","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T05:44:54.618570Z","iopub.execute_input":"2025-11-27T05:44:54.618868Z","iopub.status.idle":"2025-11-27T05:44:54.623467Z","shell.execute_reply.started":"2025-11-27T05:44:54.618845Z","shell.execute_reply":"2025-11-27T05:44:54.622551Z"}},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":"## Train the network","metadata":{}},{"cell_type":"code","source":"for epoch in range(epochs):\n    for batch_idx, (data, targets) in enumerate(train_loader):\n\n        # Get the data to CUDA if possible\n        data = data.to(device = device).squeeze(1)\n        targets = targets.to(device = device)\n\n        # forward\n        scores = model(data)\n        loss = criterion(scores, targets)\n\n        # backward\n        optimizer.zero_grad()\n        loss.backward()\n\n        # Gradient Descent or Adam step\n        optimizer.step()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T05:46:12.317348Z","iopub.execute_input":"2025-11-27T05:46:12.318060Z","iopub.status.idle":"2025-11-27T05:46:53.394501Z","shell.execute_reply.started":"2025-11-27T05:46:12.318035Z","shell.execute_reply":"2025-11-27T05:46:53.393599Z"}},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":"## Check the accuracy on training and testig data","metadata":{}},{"cell_type":"code","source":"def check_accuracy(loader, model):\n    if loader.dataset.train:\n        print(\"Checking accuracy on traning data\")\n    else:\n        print(\"Checking accuracy on testing data\")\n\n    num_correct = 0\n    num_samples = 0\n\n    model.eval()\n\n    with torch.no_grad():\n        for x, y in loader:\n            x = x.to(device = device)\n            y = y.to(device = device)\n\n            scores = model(x)\n            _, predictions = scores.max(1)\n            num_correct += (predictions == y).sum()\n            num_samples += predictions.size(0)\n\n        print(float(num_crrect)/float(num_samples)*100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T05:46:53.395949Z","iopub.execute_input":"2025-11-27T05:46:53.396265Z","iopub.status.idle":"2025-11-27T05:46:53.401944Z","shell.execute_reply.started":"2025-11-27T05:46:53.396239Z","shell.execute_reply":"2025-11-27T05:46:53.401228Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"model.train()\n\ncheck_accuracy(train_loader, model)\ncheck_accuracy(test_loader, model)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}