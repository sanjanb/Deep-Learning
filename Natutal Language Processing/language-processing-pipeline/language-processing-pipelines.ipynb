{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import spacy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T12:48:35.690879Z","iopub.execute_input":"2025-11-24T12:48:35.691205Z","iopub.status.idle":"2025-11-24T12:48:45.247372Z","shell.execute_reply.started":"2025-11-24T12:48:35.691175Z","shell.execute_reply":"2025-11-24T12:48:45.246658Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"nlp = spacy.blank('en')\n\ndoc = nlp(\"Captain america ate 100$ of samosa. Then he said I can do this all day.\")\n\nfor token in doc:\n    print(token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T12:49:07.208760Z","iopub.execute_input":"2025-11-24T12:49:07.209287Z","iopub.status.idle":"2025-11-24T12:49:07.734141Z","shell.execute_reply.started":"2025-11-24T12:49:07.209250Z","shell.execute_reply":"2025-11-24T12:49:07.733140Z"}},"outputs":[{"name":"stdout","text":"Captain\namerica\nate\n100\n$\nof\nsamosa\n.\nThen\nhe\nsaid\nI\ncan\ndo\nthis\nall\nday\n.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"As you know, the pipeline is blank here, lets check once","metadata":{}},{"cell_type":"code","source":"nlp.pipe_names","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T12:49:48.910007Z","iopub.execute_input":"2025-11-24T12:49:48.910406Z","iopub.status.idle":"2025-11-24T12:49:48.916787Z","shell.execute_reply.started":"2025-11-24T12:49:48.910379Z","shell.execute_reply":"2025-11-24T12:49:48.916089Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"Lets install a trained pipeline and load it to perform different operations","metadata":{}},{"cell_type":"code","source":"!python -m spacy download en_core_web_sm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T12:50:59.614380Z","iopub.execute_input":"2025-11-24T12:50:59.614697Z","iopub.status.idle":"2025-11-24T12:51:09.164615Z","shell.execute_reply.started":"2025-11-24T12:50:59.614671Z","shell.execute_reply":"2025-11-24T12:51:09.163410Z"}},"outputs":[{"name":"stdout","text":"Collecting en-core-web-sm==3.8.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"nlp = spacy.load('en_core_web_sm')\n\ndoc = nlp(\"Captain america ate 100$ of samosa. Then he said I can do this all day.\")\n\nfor token in doc:\n    print(token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T12:51:24.300316Z","iopub.execute_input":"2025-11-24T12:51:24.300641Z","iopub.status.idle":"2025-11-24T12:51:25.037442Z","shell.execute_reply.started":"2025-11-24T12:51:24.300614Z","shell.execute_reply":"2025-11-24T12:51:25.036633Z"}},"outputs":[{"name":"stdout","text":"Captain\namerica\nate\n100\n$\nof\nsamosa\n.\nThen\nhe\nsaid\nI\ncan\ndo\nthis\nall\nday\n.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"nlp.pipe_names \n\n# These are the pipeline this trained pipeline contains these things","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T12:52:19.076959Z","iopub.execute_input":"2025-11-24T12:52:19.077780Z","iopub.status.idle":"2025-11-24T12:52:19.083133Z","shell.execute_reply.started":"2025-11-24T12:52:19.077744Z","shell.execute_reply":"2025-11-24T12:52:19.082150Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"nlp.pipeline\n\n# What are all these pipelines means","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T12:52:36.249271Z","iopub.execute_input":"2025-11-24T12:52:36.249571Z","iopub.status.idle":"2025-11-24T12:52:36.255287Z","shell.execute_reply.started":"2025-11-24T12:52:36.249548Z","shell.execute_reply":"2025-11-24T12:52:36.254434Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x7d58dcb36870>),\n ('tagger', <spacy.pipeline.tagger.Tagger at 0x7d58dc8ad850>),\n ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x7d58dc945620>),\n ('attribute_ruler',\n  <spacy.pipeline.attributeruler.AttributeRuler at 0x7d58dcb45990>),\n ('lemmatizer',\n  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x7d58dc65b490>),\n ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x7d58dc9457e0>)]"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"doc = nlp(\"Captain america ate 100$ of samosa. Then he said I can do this all day.\")\n\nfor token in doc:\n    print(token, \"|\", token.pos_, \"|\", token.lemma_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T12:53:45.905247Z","iopub.execute_input":"2025-11-24T12:53:45.905895Z","iopub.status.idle":"2025-11-24T12:53:45.922132Z","shell.execute_reply.started":"2025-11-24T12:53:45.905866Z","shell.execute_reply":"2025-11-24T12:53:45.921192Z"}},"outputs":[{"name":"stdout","text":"Captain | PROPN | Captain\namerica | PROPN | america\nate | VERB | eat\n100 | NUM | 100\n$ | NUM | $\nof | ADP | of\nsamosa | PROPN | samosa\n. | PUNCT | .\nThen | ADV | then\nhe | PRON | he\nsaid | VERB | say\nI | PRON | I\ncan | AUX | can\ndo | VERB | do\nthis | PRON | this\nall | DET | all\nday | NOUN | day\n. | PUNCT | .\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"The above printed values are the POS - Parts of Speech that is defined in the spacy library\n- word\n- which type of word it is\n- and what  is its base form","metadata":{}},{"cell_type":"markdown","source":"### Named Entity Recognition","metadata":{}},{"cell_type":"code","source":"\ndoc = nlp(\"Tesla Inc is going to acquire twitter for $45 billion\")\n\nfor ent in doc.ents:\n    print(ent.text,\"|\", ent.label_,\"|\", spacy.explain(ent.label_))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T12:57:39.276171Z","iopub.execute_input":"2025-11-24T12:57:39.276489Z","iopub.status.idle":"2025-11-24T12:57:39.290201Z","shell.execute_reply.started":"2025-11-24T12:57:39.276465Z","shell.execute_reply":"2025-11-24T12:57:39.289444Z"}},"outputs":[{"name":"stdout","text":"Tesla Inc | ORG | Companies, agencies, institutions, etc.\n$45 billion | MONEY | Monetary values, including unit\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"### To make it look better","metadata":{}},{"cell_type":"code","source":"from spacy import displacy\n\ndisplacy.render(doc, style='ent')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:00:19.740154Z","iopub.execute_input":"2025-11-24T13:00:19.740762Z","iopub.status.idle":"2025-11-24T13:00:19.748854Z","shell.execute_reply.started":"2025-11-24T13:00:19.740738Z","shell.execute_reply":"2025-11-24T13:00:19.747676Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Tesla Inc\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n</mark>\n is going to acquire twitter for \n<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    $45 billion\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n</mark>\n</div></span>"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"### Adding a component to a blank pipeline","metadata":{}},{"cell_type":"code","source":"source_nlp = spacy.load(\"en_core_web_sm\")\n\nnlp = spacy.blank(\"en\")\nnlp.add_pipe(\"ner\",source = source_nlp)\n\nnlp.pipe_names","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:07:28.561367Z","iopub.execute_input":"2025-11-24T13:07:28.562748Z","iopub.status.idle":"2025-11-24T13:07:29.488054Z","shell.execute_reply.started":"2025-11-24T13:07:28.562682Z","shell.execute_reply":"2025-11-24T13:07:29.487088Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"['ner']"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"doc = nlp(\"Tesla Inc is going to acquire twitter for $45 billion\")\nfor ent in doc.ents:\n    print(ent.text, ent.label_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:08:06.140439Z","iopub.execute_input":"2025-11-24T13:08:06.140759Z","iopub.status.idle":"2025-11-24T13:08:06.153904Z","shell.execute_reply.started":"2025-11-24T13:08:06.140730Z","shell.execute_reply":"2025-11-24T13:08:06.153005Z"}},"outputs":[{"name":"stdout","text":"Tesla Inc ORG\n$45 billion MONEY\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"We have sucessfully added the a new component to the blank pipline, and we can create our own customizable pipelines","metadata":{}}]}