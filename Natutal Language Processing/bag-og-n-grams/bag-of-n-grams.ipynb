{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:31:06.666772Z","iopub.execute_input":"2025-12-08T14:31:06.667477Z","iopub.status.idle":"2025-12-08T14:31:06.672145Z","shell.execute_reply.started":"2025-12-08T14:31:06.667447Z","shell.execute_reply":"2025-12-08T14:31:06.671328Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:31:08.918573Z","iopub.execute_input":"2025-12-08T14:31:08.919180Z","iopub.status.idle":"2025-12-08T14:31:08.923488Z","shell.execute_reply.started":"2025-12-08T14:31:08.919153Z","shell.execute_reply":"2025-12-08T14:31:08.922585Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Default n-gram for this library of CountVectorizer is 1\n\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nv = CountVectorizer()\nv.fit([\"Thor Hathodawala is looking for a job\"])\nv.vocabulary_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:39:45.456747Z","iopub.execute_input":"2025-12-08T14:39:45.457131Z","iopub.status.idle":"2025-12-08T14:39:45.470856Z","shell.execute_reply.started":"2025-12-08T14:39:45.457106Z","shell.execute_reply":"2025-12-08T14:39:45.470204Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"{'thor': 5, 'hathodawala': 1, 'is': 2, 'looking': 4, 'for': 0, 'job': 3}"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# This is for n-gram 1 and 2(bigrams)\n\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nv = CountVectorizer(ngram_range = (1, 2))\nv.fit([\"Thor Hathodawala is looking for a job\"])\nv.vocabulary_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:41:21.352108Z","iopub.execute_input":"2025-12-08T14:41:21.352677Z","iopub.status.idle":"2025-12-08T14:41:21.359799Z","shell.execute_reply.started":"2025-12-08T14:41:21.352652Z","shell.execute_reply":"2025-12-08T14:41:21.358892Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'thor': 9,\n 'hathodawala': 2,\n 'is': 4,\n 'looking': 7,\n 'for': 0,\n 'job': 6,\n 'thor hathodawala': 10,\n 'hathodawala is': 3,\n 'is looking': 5,\n 'looking for': 8,\n 'for job': 1}"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# This is for n-gram 1 and 3 (trigrams)\n\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nv = CountVectorizer(ngram_range = (1, 3))\nv.fit([\"Thor Hathodawala is looking for a job\"])\nv.vocabulary_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:41:42.780682Z","iopub.execute_input":"2025-12-08T14:41:42.781482Z","iopub.status.idle":"2025-12-08T14:41:42.788430Z","shell.execute_reply.started":"2025-12-08T14:41:42.781451Z","shell.execute_reply":"2025-12-08T14:41:42.787746Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'thor': 12,\n 'hathodawala': 2,\n 'is': 5,\n 'looking': 9,\n 'for': 0,\n 'job': 8,\n 'thor hathodawala': 13,\n 'hathodawala is': 3,\n 'is looking': 6,\n 'looking for': 10,\n 'for job': 1,\n 'thor hathodawala is': 14,\n 'hathodawala is looking': 4,\n 'is looking for': 7,\n 'looking for job': 11}"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# This is a copus to use in the pipeline, to showcase how a text can be converted to vector\n\ncorpus = [\n    \"Thor ate pizza\",\n    \"Loki is tall\",\n    \"Loki is eating pizza\"\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:43:10.834341Z","iopub.execute_input":"2025-12-08T14:43:10.834653Z","iopub.status.idle":"2025-12-08T14:43:10.838576Z","shell.execute_reply.started":"2025-12-08T14:43:10.834632Z","shell.execute_reply":"2025-12-08T14:43:10.837790Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import spacy\n\n# load english language model and create nlp object from it\nnlp = spacy.load(\"en_core_web_sm\") \n\ndef preprocess(text):\n    # remove stop words and lemmatize the text\n    doc = nlp(text)\n    filtered_tokens = []\n    for token in doc:\n        if token.is_stop or token.is_punct:\n            continue\n        filtered_tokens.append(token.lemma_)\n    \n    return \" \".join(filtered_tokens) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:48:53.868734Z","iopub.execute_input":"2025-12-08T14:48:53.869028Z","iopub.status.idle":"2025-12-08T14:48:54.494159Z","shell.execute_reply.started":"2025-12-08T14:48:53.869006Z","shell.execute_reply":"2025-12-08T14:48:54.493268Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"corpus_processed = [preprocess(text) for text in corpus]\n\ncorpus_processed\n\n# now we have processed text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:48:54.904244Z","iopub.execute_input":"2025-12-08T14:48:54.904547Z","iopub.status.idle":"2025-12-08T14:48:54.930760Z","shell.execute_reply.started":"2025-12-08T14:48:54.904523Z","shell.execute_reply":"2025-12-08T14:48:54.929959Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"['thor eat pizza', 'Loki tall', 'Loki eat pizza']"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"# Now we use count vectorizer\n\nv = CountVectorizer(ngram_range = (1, 2))\nv.fit(corpus_processed)\nv.vocabulary_\n\n# now we have vocabularay in our hand","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:50:43.173708Z","iopub.execute_input":"2025-12-08T14:50:43.174541Z","iopub.status.idle":"2025-12-08T14:50:43.181436Z","shell.execute_reply.started":"2025-12-08T14:50:43.174515Z","shell.execute_reply":"2025-12-08T14:50:43.180590Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"{'thor': 7,\n 'eat': 0,\n 'pizza': 5,\n 'thor eat': 8,\n 'eat pizza': 1,\n 'loki': 2,\n 'tall': 6,\n 'loki tall': 4,\n 'loki eat': 3}"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"v.transform([\"Thor ate a pizza\"]).toarray()\n\n# Compare this to our own made vocabulary in the above cell's output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:51:56.164354Z","iopub.execute_input":"2025-12-08T14:51:56.164999Z","iopub.status.idle":"2025-12-08T14:51:56.170444Z","shell.execute_reply.started":"2025-12-08T14:51:56.164971Z","shell.execute_reply":"2025-12-08T14:51:56.169777Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"array([[0, 0, 0, 0, 0, 1, 0, 1, 0]])"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"v.transform([\"Hulk ate a pizza\"]).toarray()\n\n# Here we don;t have hulk in our vocab, so the first vector is 0, that is called out of vocabulary(oov)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:52:18.501652Z","iopub.execute_input":"2025-12-08T14:52:18.501997Z","iopub.status.idle":"2025-12-08T14:52:18.507480Z","shell.execute_reply.started":"2025-12-08T14:52:18.501974Z","shell.execute_reply":"2025-12-08T14:52:18.506823Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"array([[0, 0, 0, 0, 0, 1, 0, 0, 0]])"},"metadata":{}}],"execution_count":24}]}