{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13846738,"sourceType":"datasetVersion","datasetId":8819695}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:40:31.615740Z","iopub.execute_input":"2025-11-24T06:40:31.616418Z","iopub.status.idle":"2025-11-24T06:40:31.939947Z","shell.execute_reply.started":"2025-11-24T06:40:31.616394Z","shell.execute_reply":"2025-11-24T06:40:31.939155Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/student-txt/students.txt\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"import spacy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:23:15.193643Z","iopub.execute_input":"2025-11-24T06:23:15.194479Z","iopub.status.idle":"2025-11-24T06:23:23.158080Z","shell.execute_reply.started":"2025-11-24T06:23:15.194449Z","shell.execute_reply":"2025-11-24T06:23:23.157318Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"The process of creating tokens is very good, to know more about it, see the documentation of the spacy lib","metadata":{}},{"cell_type":"code","source":"doc = nlp('''\n\"Let's go to N.Y.!\"\n''')\n\nfor token in doc:\n    print(token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:31:52.723115Z","iopub.execute_input":"2025-11-24T06:31:52.724011Z","iopub.status.idle":"2025-11-24T06:31:52.729488Z","shell.execute_reply.started":"2025-11-24T06:31:52.723980Z","shell.execute_reply":"2025-11-24T06:31:52.728489Z"}},"outputs":[{"name":"stdout","text":"\n\n\"\nLet\n's\ngo\nto\nN.Y.\n!\n\"\n\n\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"Creating a instance of a spacy to do the oprations, and it is so much easy that just using a small for loop will get you the tokens used here","metadata":{}},{"cell_type":"code","source":"nlp = spacy.blank(\"en\")\n\ndoc = nlp(\"Dr. Strange loves pav bhaji of mumbai as it costs only 2$ per plate.\")\n\nfor token in doc:\n    print(token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:32:45.215146Z","iopub.execute_input":"2025-11-24T06:32:45.215488Z","iopub.status.idle":"2025-11-24T06:32:45.368133Z","shell.execute_reply.started":"2025-11-24T06:32:45.215464Z","shell.execute_reply":"2025-11-24T06:32:45.367335Z"}},"outputs":[{"name":"stdout","text":"Dr.\nStrange\nloves\npav\nbhaji\nof\nmumbai\nas\nit\ncosts\nonly\n2\n$\nper\nplate\n.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"doc[1:8] # Spanning perticular words using slice operations","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:33:09.970211Z","iopub.execute_input":"2025-11-24T06:33:09.970537Z","iopub.status.idle":"2025-11-24T06:33:09.976727Z","shell.execute_reply.started":"2025-11-24T06:33:09.970508Z","shell.execute_reply":"2025-11-24T06:33:09.975602Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Strange loves pav bhaji of mumbai as"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"doc = nlp(\"Tony agve two $ to Peter\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:36:07.259978Z","iopub.execute_input":"2025-11-24T06:36:07.260485Z","iopub.status.idle":"2025-11-24T06:36:07.264451Z","shell.execute_reply.started":"2025-11-24T06:36:07.260461Z","shell.execute_reply":"2025-11-24T06:36:07.263648Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"token0 = doc[0]\ntoken0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:36:08.085496Z","iopub.execute_input":"2025-11-24T06:36:08.086156Z","iopub.status.idle":"2025-11-24T06:36:08.092167Z","shell.execute_reply.started":"2025-11-24T06:36:08.086127Z","shell.execute_reply":"2025-11-24T06:36:08.091502Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"Tony"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"type(token0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:36:08.750098Z","iopub.execute_input":"2025-11-24T06:36:08.750396Z","iopub.status.idle":"2025-11-24T06:36:08.755355Z","shell.execute_reply.started":"2025-11-24T06:36:08.750374Z","shell.execute_reply":"2025-11-24T06:36:08.754671Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"spacy.tokens.token.Token"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"dir(token0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:34:19.740670Z","iopub.execute_input":"2025-11-24T06:34:19.740992Z","iopub.status.idle":"2025-11-24T06:34:19.748045Z","shell.execute_reply.started":"2025-11-24T06:34:19.740968Z","shell.execute_reply":"2025-11-24T06:34:19.747035Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"['_',\n '__bytes__',\n '__class__',\n '__delattr__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__getstate__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__len__',\n '__lt__',\n '__ne__',\n '__new__',\n '__pyx_vtable__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__unicode__',\n 'ancestors',\n 'check_flag',\n 'children',\n 'cluster',\n 'conjuncts',\n 'dep',\n 'dep_',\n 'doc',\n 'ent_id',\n 'ent_id_',\n 'ent_iob',\n 'ent_iob_',\n 'ent_kb_id',\n 'ent_kb_id_',\n 'ent_type',\n 'ent_type_',\n 'get_extension',\n 'has_dep',\n 'has_extension',\n 'has_head',\n 'has_morph',\n 'has_vector',\n 'head',\n 'i',\n 'idx',\n 'iob_strings',\n 'is_alpha',\n 'is_ancestor',\n 'is_ascii',\n 'is_bracket',\n 'is_currency',\n 'is_digit',\n 'is_left_punct',\n 'is_lower',\n 'is_oov',\n 'is_punct',\n 'is_quote',\n 'is_right_punct',\n 'is_sent_end',\n 'is_sent_start',\n 'is_space',\n 'is_stop',\n 'is_title',\n 'is_upper',\n 'lang',\n 'lang_',\n 'left_edge',\n 'lefts',\n 'lemma',\n 'lemma_',\n 'lex',\n 'lex_id',\n 'like_email',\n 'like_num',\n 'like_url',\n 'lower',\n 'lower_',\n 'morph',\n 'n_lefts',\n 'n_rights',\n 'nbor',\n 'norm',\n 'norm_',\n 'orth',\n 'orth_',\n 'pos',\n 'pos_',\n 'prefix',\n 'prefix_',\n 'prob',\n 'rank',\n 'remove_extension',\n 'right_edge',\n 'rights',\n 'sent',\n 'sent_start',\n 'sentiment',\n 'set_extension',\n 'set_morph',\n 'shape',\n 'shape_',\n 'similarity',\n 'subtree',\n 'suffix',\n 'suffix_',\n 'tag',\n 'tag_',\n 'tensor',\n 'text',\n 'text_with_ws',\n 'vector',\n 'vector_norm',\n 'vocab',\n 'whitespace_']"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"There are many classes of operations that we can do on this token0 instance","metadata":{}},{"cell_type":"code","source":"token0.is_alpha","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:36:13.230050Z","iopub.execute_input":"2025-11-24T06:36:13.230363Z","iopub.status.idle":"2025-11-24T06:36:13.235776Z","shell.execute_reply.started":"2025-11-24T06:36:13.230340Z","shell.execute_reply":"2025-11-24T06:36:13.234975Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"token0.like_num","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:36:13.389999Z","iopub.execute_input":"2025-11-24T06:36:13.390754Z","iopub.status.idle":"2025-11-24T06:36:13.396414Z","shell.execute_reply.started":"2025-11-24T06:36:13.390727Z","shell.execute_reply":"2025-11-24T06:36:13.395490Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"token2 = doc[2]\ntoken2.text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:36:23.975066Z","iopub.execute_input":"2025-11-24T06:36:23.975371Z","iopub.status.idle":"2025-11-24T06:36:23.981137Z","shell.execute_reply.started":"2025-11-24T06:36:23.975350Z","shell.execute_reply":"2025-11-24T06:36:23.980332Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"'two'"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"token2.like_num # the spacy knows even the numbre is in string it is a number","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:36:52.185355Z","iopub.execute_input":"2025-11-24T06:36:52.185691Z","iopub.status.idle":"2025-11-24T06:36:52.191059Z","shell.execute_reply.started":"2025-11-24T06:36:52.185667Z","shell.execute_reply":"2025-11-24T06:36:52.190318Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"token3 = doc[3]\ntoken3.text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:37:05.772661Z","iopub.execute_input":"2025-11-24T06:37:05.772943Z","iopub.status.idle":"2025-11-24T06:37:05.778280Z","shell.execute_reply.started":"2025-11-24T06:37:05.772925Z","shell.execute_reply":"2025-11-24T06:37:05.777522Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"'$'"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"token3.is_currency","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:37:15.885203Z","iopub.execute_input":"2025-11-24T06:37:15.885517Z","iopub.status.idle":"2025-11-24T06:37:15.891135Z","shell.execute_reply.started":"2025-11-24T06:37:15.885494Z","shell.execute_reply":"2025-11-24T06:37:15.890285Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"token3.like_num","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:37:27.395488Z","iopub.execute_input":"2025-11-24T06:37:27.395834Z","iopub.status.idle":"2025-11-24T06:37:27.400774Z","shell.execute_reply.started":"2025-11-24T06:37:27.395808Z","shell.execute_reply":"2025-11-24T06:37:27.400058Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"for token in doc:\n    print(token, \"==>\", \"index: \", token.i, \"is_alpha:\", token.is_alpha, \n          \"is_punct:\", token.is_punct, \n          \"like_num:\", token.like_num,\n          \"is_currency:\", token.is_currency,\n         )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:37:49.945315Z","iopub.execute_input":"2025-11-24T06:37:49.945680Z","iopub.status.idle":"2025-11-24T06:37:49.951258Z","shell.execute_reply.started":"2025-11-24T06:37:49.945654Z","shell.execute_reply":"2025-11-24T06:37:49.950202Z"}},"outputs":[{"name":"stdout","text":"Tony ==> index:  0 is_alpha: True is_punct: False like_num: False is_currency: False\nagve ==> index:  1 is_alpha: True is_punct: False like_num: False is_currency: False\ntwo ==> index:  2 is_alpha: True is_punct: False like_num: True is_currency: False\n$ ==> index:  3 is_alpha: False is_punct: False like_num: False is_currency: True\nto ==> index:  4 is_alpha: True is_punct: False like_num: False is_currency: False\nPeter ==> index:  5 is_alpha: True is_punct: False like_num: False is_currency: False\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"### Collect the emails from the doc","metadata":{}},{"cell_type":"code","source":"with open(\"/kaggle/input/student-txt/students.txt\") as f:\n    text = f.readlines()\ntext","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:40:48.445093Z","iopub.execute_input":"2025-11-24T06:40:48.445392Z","iopub.status.idle":"2025-11-24T06:40:48.452303Z","shell.execute_reply.started":"2025-11-24T06:40:48.445372Z","shell.execute_reply":"2025-11-24T06:40:48.451603Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"['Dayton high school, 8th grade students information\\n',\n '==================================================\\n',\n '\\n',\n 'Name\\tbirth day   \\temail\\n',\n '-----\\t------------\\t------\\n',\n 'Virat   5 June, 1882    virat@kohli.com\\n',\n 'Maria\\t12 April, 2001  maria@sharapova.com\\n',\n 'Serena  24 June, 1998   serena@williams.com \\n',\n 'Joe      1 May, 1997    joe@root.com\\n',\n '\\n',\n '\\n',\n '\\n']"},"metadata":{}}],"execution_count":35},{"cell_type":"markdown","source":"Lets convert this into big string","metadata":{}},{"cell_type":"code","source":"text = ' '.join(text)\ntext","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:41:32.520499Z","iopub.execute_input":"2025-11-24T06:41:32.521218Z","iopub.status.idle":"2025-11-24T06:41:32.526301Z","shell.execute_reply.started":"2025-11-24T06:41:32.521184Z","shell.execute_reply":"2025-11-24T06:41:32.525599Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"'Dayton high school, 8th grade students information\\n ==================================================\\n \\n Name\\tbirth day   \\temail\\n -----\\t------------\\t------\\n Virat   5 June, 1882    virat@kohli.com\\n Maria\\t12 April, 2001  maria@sharapova.com\\n Serena  24 June, 1998   serena@williams.com \\n Joe      1 May, 1997    joe@root.com\\n \\n \\n \\n'"},"metadata":{}}],"execution_count":36},{"cell_type":"markdown","source":"This spacy is very powerful to do the below kind of operations","metadata":{}},{"cell_type":"code","source":"doc = nlp(text)\nemails = []\n\nfor token in doc:\n    if token.like_email:\n        print(token.text)\n        emails.append(token.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:42:49.360439Z","iopub.execute_input":"2025-11-24T06:42:49.360822Z","iopub.status.idle":"2025-11-24T06:42:49.369320Z","shell.execute_reply.started":"2025-11-24T06:42:49.360799Z","shell.execute_reply":"2025-11-24T06:42:49.368363Z"}},"outputs":[{"name":"stdout","text":"virat@kohli.com\nmaria@sharapova.com\nserena@williams.com\njoe@root.com\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"### Lets do it for hindi","metadata":{}},{"cell_type":"code","source":"nlp = spacy.blank(\"hi\")\n\n\ndoc = nlp(\"भैया जी! 5000 ₹ उधार थे वो वापस देदो\")\nfor token in doc:\n    print(token, token.is_currency)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:45:34.840185Z","iopub.execute_input":"2025-11-24T06:45:34.840989Z","iopub.status.idle":"2025-11-24T06:45:34.903064Z","shell.execute_reply.started":"2025-11-24T06:45:34.840963Z","shell.execute_reply":"2025-11-24T06:45:34.902329Z"}},"outputs":[{"name":"stdout","text":"भैया False\nजी False\n! False\n5000 False\n₹ True\nउधार False\nथे False\nवो False\nवापस False\nदेदो False\n","output_type":"stream"}],"execution_count":39},{"cell_type":"markdown","source":"### Customizing tokenizer","metadata":{}},{"cell_type":"code","source":"nlp = spacy.blank(\"en\")\n\ndoc = nlp('gimme double cheese extra large healthy pizza')\ntokens = [token.text for token in doc]\ntokens","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:48:28.061185Z","iopub.execute_input":"2025-11-24T06:48:28.061702Z","iopub.status.idle":"2025-11-24T06:48:28.223318Z","shell.execute_reply.started":"2025-11-24T06:48:28.061676Z","shell.execute_reply":"2025-11-24T06:48:28.222644Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"['gimme', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"},"metadata":{}}],"execution_count":40},{"cell_type":"markdown","source":"As you can see above, gimme is two words give me but the tokenizer did it as one","metadata":{}},{"cell_type":"code","source":"from spacy.symbols import ORTH\n\nnlp = spacy.blank(\"en\")\ndoc = nlp(\"gimme double cheese extra large healthy pizza\")\ntokens = [token.text for token in doc]\ntokens","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:49:17.685447Z","iopub.execute_input":"2025-11-24T06:49:17.685770Z","iopub.status.idle":"2025-11-24T06:49:17.838393Z","shell.execute_reply.started":"2025-11-24T06:49:17.685747Z","shell.execute_reply":"2025-11-24T06:49:17.837732Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"['gimme', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"nlp.tokenizer.add_special_case(\"gimme\", [\n    {ORTH: \"gim\"},\n    {ORTH: \"me\"},\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:50:02.560213Z","iopub.execute_input":"2025-11-24T06:50:02.560533Z","iopub.status.idle":"2025-11-24T06:50:02.565542Z","shell.execute_reply.started":"2025-11-24T06:50:02.560501Z","shell.execute_reply":"2025-11-24T06:50:02.564596Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"doc = nlp(\"gimme double cheese extra large healthy pizza\")\ntokens = [token.text for token in doc]\ntokens","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:50:02.680081Z","iopub.execute_input":"2025-11-24T06:50:02.680395Z","iopub.status.idle":"2025-11-24T06:50:02.686610Z","shell.execute_reply.started":"2025-11-24T06:50:02.680371Z","shell.execute_reply":"2025-11-24T06:50:02.685776Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"['gim', 'me', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"},"metadata":{}}],"execution_count":45},{"cell_type":"markdown","source":"Now the gimme is tokenized to gim and me","metadata":{}},{"cell_type":"markdown","source":"### Sentence Tokenization or Segmentation","metadata":{}},{"cell_type":"code","source":"doc = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")\nfor sentence in doc.sents:\n    print(sentence)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:50:51.095871Z","iopub.execute_input":"2025-11-24T06:50:51.096494Z","iopub.status.idle":"2025-11-24T06:50:51.137425Z","shell.execute_reply.started":"2025-11-24T06:50:51.096466Z","shell.execute_reply":"2025-11-24T06:50:51.136421Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_48/1129431677.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/spacy/tokens/doc.pyx\u001b[0m in \u001b[0;36msents\u001b[0;34m()\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: [E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`."],"ename":"ValueError","evalue":"[E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`.","output_type":"error"}],"execution_count":46},{"cell_type":"code","source":"nlp.add_pipe(\"sentencizer\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:52:00.840525Z","iopub.execute_input":"2025-11-24T06:52:00.841223Z","iopub.status.idle":"2025-11-24T06:52:00.853679Z","shell.execute_reply.started":"2025-11-24T06:52:00.841190Z","shell.execute_reply":"2025-11-24T06:52:00.852946Z"}},"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"<spacy.pipeline.sentencizer.Sentencizer at 0x7f4203f53f90>"},"metadata":{}}],"execution_count":48},{"cell_type":"markdown","source":"Once you add the above pipeline component to the pipeline, then we'll get rid of the error","metadata":{}},{"cell_type":"code","source":"nlp.pipe_names","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:51:31.160070Z","iopub.execute_input":"2025-11-24T06:51:31.160386Z","iopub.status.idle":"2025-11-24T06:51:31.165892Z","shell.execute_reply.started":"2025-11-24T06:51:31.160362Z","shell.execute_reply":"2025-11-24T06:51:31.165215Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}],"execution_count":47},{"cell_type":"markdown","source":"the pipeline was blank, that is why we are getting the above error","metadata":{}},{"cell_type":"markdown","source":"like this","metadata":{}},{"cell_type":"code","source":"nlp.pipe_names","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:52:08.114967Z","iopub.execute_input":"2025-11-24T06:52:08.115358Z","iopub.status.idle":"2025-11-24T06:52:08.120333Z","shell.execute_reply.started":"2025-11-24T06:52:08.115334Z","shell.execute_reply":"2025-11-24T06:52:08.119599Z"}},"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"['sentencizer']"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"doc = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")\nfor sentence in doc.sents:\n    print(sentence)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:53:18.274968Z","iopub.execute_input":"2025-11-24T06:53:18.275251Z","iopub.status.idle":"2025-11-24T06:53:18.279972Z","shell.execute_reply.started":"2025-11-24T06:53:18.275231Z","shell.execute_reply":"2025-11-24T06:53:18.279138Z"}},"outputs":[{"name":"stdout","text":"Dr. Strange loves pav bhaji of mumbai.\nHulk loves chat of delhi\n","output_type":"stream"}],"execution_count":50},{"cell_type":"markdown","source":"Now it is working properly","metadata":{}},{"cell_type":"markdown","source":"## Exercise\n\n(1) Think stats is a free book to study statistics (https://greenteapress.com/thinkstats2/thinkstats2.pdf)\n\nThis book has references to many websites from where you can download free datasets. You are an NLP engineer working for some company and you want to collect all dataset websites from this book. To keep exercise simple you are given a paragraph from this book and you want to grab all urls from this paragraph using spacy","metadata":{}},{"cell_type":"code","source":"text='''\nLook for data to help you address the question. Governments are good\nsources because data from public research is often freely available. Good\nplaces to start include http://www.data.gov/, and http://www.science.\ngov/, and in the United Kingdom, http://data.gov.uk/.\nTwo of my favorite data sets are the General Social Survey at http://www3.norc.org/gss+website/, \nand the European Social Survey at http://www.europeansocialsurvey.org/.\n'''\n\n# TODO: Write code here\n# Hint: token has an attribute that can be used to detect a url\n\ndoc = nlp(text)\n\nfor token in doc:\n    if token.like_url:\n        print(token.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:55:54.621453Z","iopub.execute_input":"2025-11-24T06:55:54.621810Z","iopub.status.idle":"2025-11-24T06:55:54.629449Z","shell.execute_reply.started":"2025-11-24T06:55:54.621786Z","shell.execute_reply":"2025-11-24T06:55:54.628537Z"}},"outputs":[{"name":"stdout","text":"http://www.data.gov/\nhttp://www.science\nhttp://data.gov.uk/.\nhttp://www3.norc.org/gss+website/\nhttp://www.europeansocialsurvey.org/.\n","output_type":"stream"}],"execution_count":52},{"cell_type":"markdown","source":"Got it mannnnnnnnn !!!!!!!","metadata":{}},{"cell_type":"code","source":"transactions = \"Tony gave two $ to Peter, Bruce gave 500 € to Steve\"\n\n# TODO: Write code here\n# Hint: Use token.i for the index of a token and token.is_currency for currency symbol detection\n\ndoc = nlp(transactions)\nfor token in doc:\n    if token.is_currency:\n        print(doc[token.i-1],token.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T06:59:12.715403Z","iopub.execute_input":"2025-11-24T06:59:12.715736Z","iopub.status.idle":"2025-11-24T06:59:12.721201Z","shell.execute_reply.started":"2025-11-24T06:59:12.715710Z","shell.execute_reply":"2025-11-24T06:59:12.720489Z"}},"outputs":[{"name":"stdout","text":"two $\n500 €\n","output_type":"stream"}],"execution_count":62},{"cell_type":"markdown","source":"Bulls eyeeeeeeeeeee !!!!!!!!!!!!!!!!","metadata":{}}]}