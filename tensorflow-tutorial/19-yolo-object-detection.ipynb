{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Intersection over Union (IoU) in YOLO**\n\n---\n\n## 1. Introduction\n\nIn **object detection**, models like **YOLO**, **Faster R-CNN**, and **SSD** predict **bounding boxes** around objects.\nTo evaluate how well a predicted box matches the ground truth, we use **Intersection over Union (IoU)**.\n\n**IoU** is a metric that measures the **overlap** between two bounding boxes:\n\n* The **predicted bounding box** from the model, and\n* The **ground truth bounding box** (actual labeled object).\n\n---\n\n## 2. Definition\n\nThe **Intersection over Union (IoU)** is defined as:\n\n[\nIoU = \\frac{\\text{Area of Overlap}}{\\text{Area of Union}}\n]\n\nThat is:\n\n[\nIoU = \\frac{|B_p \\cap B_{gt}|}{|B_p \\cup B_{gt}|}\n]\n\nWhere:\n\n* ( B_p ): predicted bounding box\n* ( B_{gt} ): ground truth bounding box\n* ( \\cap ): intersection area (common area between boxes)\n* ( \\cup ): union area (combined area of both boxes)\n\n---\n\n## 3. Intuition\n\n* **IoU = 1.0** → perfect overlap (prediction is exactly correct).\n* **IoU = 0.0** → no overlap (completely wrong).\n* **IoU between 0.5–0.7** → usually considered a *good* detection in benchmarks.\n\n---\n\n## 4. IoU in YOLO\n\nIn **YOLO (You Only Look Once)**, IoU plays two main roles:\n\n### (a) During Training\n\nYOLO divides the image into grids (e.g., 13×13, 19×19).\nEach cell predicts multiple **anchor boxes** (predefined aspect ratios).\n\nFor each ground-truth object:\n\n* YOLO computes IoU between the object and all anchors.\n* The anchor with the **highest IoU** is assigned to predict that object.\n\nThis ensures:\n\n* Each object is detected by **only one anchor box**.\n* Anchors specialize in detecting objects of certain sizes or shapes.\n\n### (b) During Inference (Post-Processing)\n\nYOLO outputs multiple bounding boxes per object.\nTo remove duplicates, YOLO applies **Non-Maximum Suppression (NMS)** based on IoU:\n\n1. Keep the box with the **highest confidence score**.\n2. Remove all other boxes that have **IoU > threshold (e.g., 0.5)** with it.\n3. Repeat until no boxes remain.\n\nThis ensures that each object is represented by only one bounding box.\n\n---\n\n## 5. Example Calculation\n\n### Given:\n\nGround Truth Box: `(x1=2, y1=2, x2=6, y2=6)`\nPredicted Box: `(x1=4, y1=4, x2=8, y2=8)`\n\n### Step 1: Find Intersection\n\nIntersection coordinates:\n\n```\nx_left = max(2, 4) = 4\ny_top = max(2, 4) = 4\nx_right = min(6, 8) = 6\ny_bottom = min(6, 8) = 6\n```\n\nIntersection area = (6 - 4) × (6 - 4) = 4\n\n### Step 2: Find Union\n\nArea of GT = 4×4 = 16\nArea of Prediction = 4×4 = 16\nUnion = 16 + 16 - 4 = 28\n\n### Step 3: IoU\n\n[\nIoU = \\frac{4}{28} = 0.1428\n]\n\nSo the IoU = **0.14** (poor match).\n\n---\n\n## 6. Python Implementation Example\n\n```python\ndef calculate_iou(box1, box2):\n    \"\"\"\n    box format: [x1, y1, x2, y2]\n    \"\"\"\n    x_left = max(box1[0], box2[0])\n    y_top = max(box1[1], box2[1])\n    x_right = min(box1[2], box2[2])\n    y_bottom = min(box1[3], box2[3])\n\n    if x_right < x_left or y_bottom < y_top:\n        return 0.0\n\n    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n\n    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n\n    union_area = box1_area + box2_area - intersection_area\n\n    iou = intersection_area / union_area\n    return iou\n\n# Example\nboxA = [2, 2, 6, 6]\nboxB = [4, 4, 8, 8]\n\nprint(\"IoU:\", calculate_iou(boxA, boxB))\n```\n\nOutput:\n\n```\nIoU: 0.14285714285714285\n```\n\n---\n\n## 7. IoU Thresholds in YOLO\n\n| IoU Threshold | Interpretation                            |\n| ------------- | ----------------------------------------- |\n| < 0.3         | Poor prediction (ignored or background)   |\n| 0.3 – 0.5     | Ambiguous region                          |\n| ≥ 0.5         | Good detection (counted as True Positive) |\n| ≥ 0.75        | High-quality detection                    |\n\nIn training metrics:\n\n* **mAP@0.5** → Mean Average Precision at IoU = 0.5\n* **mAP@0.5:0.95** → Mean AP averaged over IoU thresholds (0.5 to 0.95, step 0.05)\n\n---\n\n## 8. IoU Variants in YOLOv5–YOLOv8\n\nYOLOv5+ introduced **IoU variants** for better localization and convergence:\n\n| Metric                     | Description                                  | Purpose                                   |\n| -------------------------- | -------------------------------------------- | ----------------------------------------- |\n| **IoU**                    | Basic overlap measure                        | Simple baseline                           |\n| **GIoU (Generalized IoU)** | Adds penalty for non-overlapping boxes       | Better gradient when boxes don’t overlap  |\n| **DIoU (Distance IoU)**    | Adds distance between box centers            | Improves localization                     |\n| **CIoU (Complete IoU)**    | Combines distance, overlap, and aspect ratio | Most effective for YOLOv5–YOLOv8 training |\n\n### CIoU Loss (used in YOLOv5)\n\n[\nL_{CIoU} = 1 - IoU + \\frac{\\rho^2(b, b^{gt})}{c^2} + \\alpha v\n]\nWhere:\n\n* ( \\rho(b, b^{gt}) ): Euclidean distance between box centers\n* ( c ): diagonal length of the smallest enclosing box\n* ( v ): aspect ratio consistency term\n* ( \\alpha ): weighting factor\n\nThis ensures boxes not only overlap but are **well-aligned and proportional**.\n\n---\n\n## 9. Visualization Example\n\n```python\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\nfig, ax = plt.subplots(1)\nax.set_xlim(0, 10)\nax.set_ylim(0, 10)\n\n# Ground truth\ngt = patches.Rectangle((2, 2), 4, 4, linewidth=2, edgecolor='g', facecolor='none', label='Ground Truth')\n# Prediction\npred = patches.Rectangle((4, 4), 4, 4, linewidth=2, edgecolor='r', facecolor='none', label='Prediction')\n\nax.add_patch(gt)\nax.add_patch(pred)\nax.legend()\nplt.gca().invert_yaxis()\nplt.title(\"IoU = 0.14 (Low Overlap)\")\nplt.show()\n```\n\n---\n\n## 10. Summary\n\n| Concept              | Description                                   |\n| -------------------- | --------------------------------------------- |\n| **IoU Definition**   | Ratio of overlap area to union area           |\n| **Used in YOLO for** | Anchor matching and NMS                       |\n| **High IoU ⇒**       | Better localization                           |\n| **IoU Thresholds**   | ≥0.5 = good detection                         |\n| **Variants**         | GIoU, DIoU, CIoU for better training feedback |\n| **In Evaluation**    | Used in mAP@IoU metrics                       |\n\n---\n\n### Key Insight\n\nIn YOLO, **IoU is the foundation** for:\n\n* Assigning anchors during training\n* Measuring localization accuracy\n* Filtering detections using NMS\n* Computing final evaluation metrics (mAP)","metadata":{}},{"cell_type":"markdown","source":"# **Non-Maximum Suppression (NMS) in YOLO**\n\n---\n\n## 1. Introduction\n\nIn object detection, models like **YOLO** predict **multiple bounding boxes** per object.\nThese predictions often **overlap heavily**, because:\n\n* Each grid cell predicts multiple anchors.\n* Nearby grid cells may detect the same object.\n\nTo keep only the **best detection per object**, YOLO applies **Non-Maximum Suppression (NMS)**.\n\n---\n\n## 2. Purpose\n\n**Goal of NMS**:\n\n* Remove duplicate bounding boxes for the same object.\n* Keep only the box with the **highest confidence score**.\n\nWithout NMS:\n\n* A single object could have 3–10 overlapping boxes.\n* Evaluation metrics like **mAP** would be artificially inflated or misleading.\n\n---\n\n## 3. How NMS Works\n\n### Step-by-step\n\n1. **Sort predictions by confidence score** (objectness × class probability).\n2. Take the **highest-scoring box** and keep it.\n3. Compute **IoU** of this box with all remaining boxes.\n4. Remove boxes with **IoU > threshold** (e.g., 0.5).\n5. Repeat steps 2–4 until no boxes remain.\n\n---\n\n### Example Workflow\n\n| Step | Boxes (with scores)              |\n| ---- | -------------------------------- |\n| 1    | B1(0.9), B2(0.8), B3(0.6)        |\n| 2    | Keep B1 (highest score 0.9)      |\n| 3    | Compute IoU(B1, B2), IoU(B1, B3) |\n| 4    | Remove boxes with IoU > 0.5      |\n| 5    | Repeat for remaining boxes       |\n\n**Result:** Only non-overlapping boxes with high confidence remain.\n\n---\n\n## 4. NMS Algorithm (Python Example)\n\n```python\nimport numpy as np\n\ndef non_max_suppression(boxes, scores, iou_threshold=0.5):\n    \"\"\"\n    boxes: list of [x1, y1, x2, y2]\n    scores: confidence scores for each box\n    \"\"\"\n    boxes = np.array(boxes)\n    scores = np.array(scores)\n    idxs = scores.argsort()[::-1]  # sort by score descending\n    keep = []\n\n    while len(idxs) > 0:\n        i = idxs[0]\n        keep.append(i)\n        if len(idxs) == 1:\n            break\n\n        # Compute IoU of highest-score box with remaining boxes\n        ious = np.array([calculate_iou(boxes[i], boxes[j]) for j in idxs[1:]])\n\n        # Keep boxes with IoU <= threshold\n        idxs = idxs[1:][ious <= iou_threshold]\n\n    return keep\n\n# Example usage\nboxes = [[2, 2, 6, 6], [4, 4, 8, 8], [10, 10, 14, 14]]\nscores = [0.9, 0.8, 0.7]\n\nkeep_idx = non_max_suppression(boxes, scores, iou_threshold=0.5)\nprint(\"Boxes to keep:\", keep_idx)\n```\n\n**Output**:\n\n```\nBoxes to keep: [0, 2]\n```\n\n---\n\n## 5. NMS in YOLO\n\n* YOLO predicts **multiple boxes per grid cell**.\n* Each box has:\n\n  * **Objectness score** (confidence that object exists)\n  * **Class probabilities** (probability for each class)\n* Final box score = **objectness × class probability**\n* NMS is applied **per class**, i.e., remove duplicates for each object class independently.\n\n### Key Parameters in YOLO:\n\n* **Confidence threshold**: Minimum score to consider a box.\n* **IoU threshold for NMS**: Remove boxes with IoU > threshold.\n\n---\n\n## 6. Soft-NMS (Optional Advanced)\n\nInstead of removing overlapping boxes completely, **Soft-NMS** reduces their scores gradually:\n\n[\nscore_i = score_i \\times (1 - IoU(B_{max}, B_i))\n]\n\n* Prevents missing detections in crowded scenes.\n* Sometimes used in **YOLOv5+** for better multi-object detection.\n\n---\n\n## 7. Visualization Example\n\n```python\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\nboxes = [[2, 2, 6, 6], [4, 4, 8, 8], [10, 10, 14, 14]]\nscores = [0.9, 0.8, 0.7]\nkeep = [0, 2]\n\nfig, ax = plt.subplots(1)\nax.set_xlim(0, 15)\nax.set_ylim(0, 15)\n\ncolors = ['g', 'r', 'b']\nfor i, box in enumerate(boxes):\n    rect = patches.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1], linewidth=2, edgecolor=colors[i], facecolor='none')\n    ax.add_patch(rect)\n    ax.text(box[0], box[1]-0.5, f\"{scores[i]:.2f}\", color=colors[i])\n\nplt.gca().invert_yaxis()\nplt.title(\"Non-Maximum Suppression Example\")\nplt.show()\n```\n\n* Green: highest score, kept\n* Red: overlapping box removed\n* Blue: separate box, kept\n\n---\n\n## 8. Summary\n\n| Concept           | Description                                                          |\n| ----------------- | -------------------------------------------------------------------- |\n| **NMS**           | Filters overlapping predictions, keeps only highest confidence boxes |\n| **IoU threshold** | Determines overlap cutoff for suppression (typical 0.5)              |\n| **Class-wise**    | NMS applied separately for each object class                         |\n| **Soft-NMS**      | Gradually decreases scores instead of hard removal                   |\n| **Used in YOLO**  | Anchor assignment post-processing, final detection refinement        |\n\n---\n\n**Key Takeaway:**\nIoU tells you **how well a predicted box matches the ground truth**, while NMS uses IoU to **eliminate duplicate detections**, ensuring each object is represented by a single, confident bounding box.","metadata":{}},{"cell_type":"markdown","source":"[https://github.com/AlexeyAB/darknet#how-to-compile-on-windows-using-cmake](http://)","metadata":{}}]}