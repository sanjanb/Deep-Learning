{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Sliding Window and R-CNN Family**\n\n---\n\n## 1. Sliding Window Object Detection\n\n### Overview\n\nBefore deep learning, **object detection** relied on a **sliding window** approach. The idea was to slide a small window (of different sizes and aspect ratios) across the image and run a **classifier** (like SVM or CNN) on each patch to decide if it contains an object.\n\n### Process\n\n1. Take the input image.\n2. Slide a fixed-size window across the image (stride = few pixels).\n3. For each window:\n\n   * Extract features (HOG, SIFT, or CNN features).\n   * Classify using a binary classifier (object vs background).\n4. Combine detections with **Non-Maximum Suppression (NMS)** to remove duplicates.\n\n### Drawbacks\n\n* **Computationally expensive**: Thousands of overlapping windows.\n* **Inefficient**: Most windows are background.\n* **Poor scalability** for multiple object categories.\n* **Fixed aspect ratios** make it difficult to detect objects of varying shapes.\n\n### Key takeaway\n\nSliding window introduced the **idea of localized detection**, but not efficiency. Deep learning-based models (R-CNN family) solved these issues.\n\n---\n\n## 2. R-CNN (Regions with CNN features)\n\n### Paper\n\n**R-CNN: Regions with Convolutional Neural Networks (2014, Ross Girshick)**\n[Paper link](https://arxiv.org/abs/1311.2524)\n\n### Main Idea\n\nInstead of checking *every window*, R-CNN uses **region proposals** — a small number (~2000) of likely object regions — and classifies each using a CNN.\n\n### Pipeline\n\n1. **Region Proposal**: Generate ~2000 candidate regions using *Selective Search*.\n2. **Feature Extraction**: For each region, resize to fixed size (e.g., 224×224) and feed into a pre-trained CNN (like AlexNet).\n3. **Classification**: Use SVM to classify each region as object class or background.\n4. **Bounding Box Regression**: Refine box coordinates.\n\n### Architecture Diagram\n\n```\nInput Image → Selective Search → CNN Feature Extractor → SVM Classifier + Box Regressor\n```\n\n### Pros\n\n* Major accuracy boost over sliding window.\n* Introduced deep features to object detection.\n\n### Cons\n\n* **Extremely slow** (≈50 seconds per image).\n* Requires saving CNN features to disk.\n* Training is multi-stage (CNN → SVM → Bounding box regressor).\n\n---\n\n## 3. Fast R-CNN (2015)\n\n### Paper\n\n**Fast R-CNN: Ross Girshick (2015)**\n[Paper link](https://arxiv.org/abs/1504.08083)\n\n### Motivation\n\nR-CNN was accurate but **too slow** because it ran CNN separately on each region.\nFast R-CNN improves efficiency by **sharing computation**.\n\n### Pipeline\n\n1. Input entire image to the **CNN once** → get a **feature map**.\n2. Use **Region of Interest (RoI) pooling** to extract region-specific features from this shared feature map.\n3. Each region’s feature vector goes into:\n\n   * A softmax classifier (for object category)\n   * A bounding box regressor (to refine coordinates)\n\n### Architecture\n\n```\nImage → CNN → Feature Map → RoI Pooling → Fully Connected Layers\n                          → (Softmax Classifier + Box Regressor)\n```\n\n### Key Component: RoI Pooling\n\n* Converts regions of arbitrary size into fixed-size feature maps (e.g., 7×7).\n* Enables shared computation across proposals.\n\n### Pros\n\n* **Much faster** than R-CNN (≈2 seconds per image).\n* **Single-stage training** (end-to-end).\n* **Higher accuracy**.\n\n### Cons\n\n* Still uses **Selective Search** for region proposals (CPU-based, slow).\n\n---\n\n## 4. Faster R-CNN (2016)\n\n### Paper\n\n**Faster R-CNN: Ren et al. (2016)**\n[Paper link](https://arxiv.org/abs/1506.01497)\n\n### Motivation\n\nFast R-CNN was still limited by the **slow region proposal step**.\nFaster R-CNN replaces Selective Search with a **Region Proposal Network (RPN)** — making the entire pipeline fully deep-learning-based and faster.\n\n### Key Innovation: Region Proposal Network (RPN)\n\n* A small CNN that slides over the feature map.\n* Predicts:\n\n  * **Objectness score** (object vs background)\n  * **Bounding box coordinates** for each anchor\n* Anchors are predefined boxes (different scales and aspect ratios).\n\n### Pipeline\n\n1. Image → CNN → Feature Map\n2. **RPN** → generates region proposals\n3. **RoI Pooling** → extract features for each proposed region\n4. **Classifier + Box Regressor** → final object detection\n\n### Architecture\n\n```\nImage → CNN Backbone\n       ├──→ Region Proposal Network → RoIs\n       └──→ RoI Pooling → Classifier + Box Regressor\n```\n\n### Training\n\n* RPN and detection network share convolutional layers.\n* Trained jointly (end-to-end).\n\n### Performance\n\n* **Speed**: ~5–10 FPS (depending on backbone)\n* **Accuracy**: Among the best for 2016–2018\n* **Used in**: Mask R-CNN, Feature Pyramid Networks, etc.\n\n### Pros\n\n* Fully deep-learning-based (no Selective Search).\n* High accuracy and speed.\n* Works on complex datasets like COCO and Open Images.\n\n### Cons\n\n* Relatively complex to train.\n* Still not real-time (compared to YOLO or SSD).\n\n---\n\n## 5. Comparison Summary\n\n| Method             | Year | Region Proposal Method  | Speed     | Accuracy  | End-to-End |\n| ------------------ | ---- | ----------------------- | --------- | --------- | ---------- |\n| **Sliding Window** | 2005 | Dense windows           | Very slow | Low       | No         |\n| **R-CNN**          | 2014 | Selective Search        | Very slow | High      | No         |\n| **Fast R-CNN**     | 2015 | Selective Search        | Moderate  | High      | Partly     |\n| **Faster R-CNN**   | 2016 | Region Proposal Network | Fast      | Very High | Yes        |\n\n---\n\n## 6. Implementation Example (PyTorch)\n\nA minimal Faster R-CNN example using `torchvision`:\n\n```python\nimport torchvision\nfrom torchvision.models.detection import FasterRCNN_ResNet50_FPN_Weights\n\n# Load pretrained Faster R-CNN\nmodel = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n    weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT\n)\n\n# Set to evaluation mode\nmodel.eval()\n\nfrom PIL import Image\nimport torchvision.transforms as T\n\n# Load and preprocess image\nimage = Image.open(\"example.jpg\").convert(\"RGB\")\ntransform = T.Compose([T.ToTensor()])\nimg = transform(image)\n\n# Run detection\nwith torch.no_grad():\n    predictions = model([img])\n\nprint(predictions[0][\"boxes\"], predictions[0][\"labels\"], predictions[0][\"scores\"])\n```\n\n---\n\n## 7. Evolution Summary\n\n```\nSliding Window → R-CNN → Fast R-CNN → Faster R-CNN → Mask R-CNN\n```\n\nEach step improved:\n\n* **Speed**: by sharing computation or removing hand-crafted methods\n* **Accuracy**: by end-to-end deep learning\n* **Scalability**: by enabling multi-class detection and segmentation\n\n---\n\n## 8. References\n\n* [R-CNN Paper (2014)](https://arxiv.org/abs/1311.2524)\n* [Fast R-CNN Paper (2015)](https://arxiv.org/abs/1504.08083)\n* [Faster R-CNN Paper (2016)](https://arxiv.org/abs/1506.01497)\n* [TorchVision Object Detection Docs](https://pytorch.org/vision/stable/models.html#object-detection)\n","metadata":{}}]}
